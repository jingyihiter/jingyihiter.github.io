<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>JingYi-Blog</title>
    <link>https://jingyihiter.github.io/</link>
    <description>Recent content on JingYi-Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 09 Apr 2017 11:45:08 +0800</lastBuildDate>
    <atom:link href="https://jingyihiter.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>爬虫模拟登录豆瓣</title>
      <link>https://jingyihiter.github.io/2017/04/09/%E7%88%AC%E8%99%AB%E6%A8%A1%E6%8B%9F%E7%99%BB%E5%BD%95%E8%B1%86%E7%93%A3</link>
      <pubDate>Sun, 09 Apr 2017 11:45:08 +0800</pubDate>
      
      <guid>https://jingyihiter.github.io/2017/04/09/%E7%88%AC%E8%99%AB%E6%A8%A1%E6%8B%9F%E7%99%BB%E5%BD%95%E8%B1%86%E7%93%A3</guid>
      <description>

&lt;h2 id=&#34;网络爬虫-模拟登录豆瓣:9e0f1c7021fb77d2438aa4a26d495c1d&#34;&gt;网络爬虫——模拟登录豆瓣&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;# -*- coding: utf-8 -*-
&amp;quot;&amp;quot;&amp;quot;
Created on Sat Apr 01 13:44:51 2017

@author: 马晶义
&amp;quot;&amp;quot;&amp;quot;

import requests
import re
headers = {
    &amp;quot;Host&amp;quot;:&amp;quot;www.douban.com&amp;quot;,
    &amp;quot;User-Agent&amp;quot;:&amp;quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36&amp;quot;,
    &amp;quot;Accept-Language&amp;quot;:&amp;quot;zh-CN,zh;q=0.8,zh-TW;q=0.6&amp;quot;,
    &amp;quot;Accept-Encoding&amp;quot;:&amp;quot;gzip, deflate, sdch, br&amp;quot;,
    &amp;quot;Connection&amp;quot;:&amp;quot;keep-alive&amp;quot;
    }

def login():
    login_str = u&#39;登录&#39;
    data = {
    #&#39;ck&#39;:&#39;GiW5&#39;,
    &#39;source&#39;:&#39;None&#39;,
    #&#39;redir&#39;:&#39;https://movie.douban.com/&#39;,
    &#39;form_email&#39;:&#39;xxxxxx&#39;,
    &#39;form_password&#39;:&#39;xxxxx&#39;,
    #&#39;captcha_solution&#39;:captcha_solution,
    #&#39;captcha_id&#39;:captcha_id,
    &#39;login&#39;:login_str
    }
    login_url = &#39;https://www.douban.com/accounts/login&#39;
    session = requests.session()
    html = session.get(login_url,headers=headers).text
    captcha_img_pattern = r&#39;(?&amp;lt;=&amp;lt;img id=&amp;quot;captcha_image&amp;quot; src=\&amp;quot;).*?(?=\&amp;quot;)&#39;
    captcha_image_url = re.search(captcha_img_pattern,html,re.S|re.M|re.I)
    if captcha_image_url is not None:
        captcha_image_url = captcha_image_url.group()
        print captcha_image_url
        #captcha_image = session.get(captcha_image_url).text
        captcha_image = requests.get(captcha_image_url,headers=headers).content
        document =&#39;login_captcha_douban.jpg&#39; 
        file_ = open(document,&#39;wb&#39;)
        file_.write(captcha_image)
        file_.close()
        captcha_solution = raw_input(&#39;captcha_solution:&#39;)
        data[&#39;captcha-solution&#39;] = captcha_solution
        #获取captcha_id
        captcha_id_pattern = r&#39;(?&amp;lt;=&amp;lt;input type=&amp;quot;hidden&amp;quot; name=&amp;quot;captcha-id&amp;quot; value=\&amp;quot;).*?(?=\&amp;quot;/&amp;gt;)&#39;
        captcha_id = re.search(captcha_id_pattern,html,re.S|re.M|re.I)
        if captcha_id is None:
            print &#39;captcha_id error&#39;
        else:
            captcha_id = captcha_id.group()
            data[&#39;captcha-id&#39;] = captcha_id
    session.post(login_url,headers=headers,data=data)
    print data
    print session.cookies.items()
    return session


def main():
    session = login()
    usinfo = session.get(&#39;https://www.douban.com/people/146365045/&#39;,headers=headers).text
    #输出你的用户名
    print (re.search(r&#39;(?&amp;lt;=&amp;lt;title&amp;gt;).*?(?=&amp;lt;/title&amp;gt;)&#39;,usinfo,re.M|re.I|re.S)).group()
    usinfo = usinfo.encode(&#39;utf-8&#39;)  #保存你个人信息页面
    file_=open(&#39;use.html&#39;,&#39;wb&#39;)
    file_.write(usinfo)
    file_.close()

main()
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>KB-QA系统paper推荐</title>
      <link>https://jingyihiter.github.io/2017/03/29/kb-qa%E7%B3%BB%E7%BB%9Fpaper%E6%8E%A8%E8%8D%90</link>
      <pubDate>Wed, 29 Mar 2017 20:43:29 +0800</pubDate>
      
      <guid>https://jingyihiter.github.io/2017/03/29/kb-qa%E7%B3%BB%E7%BB%9Fpaper%E6%8E%A8%E8%8D%90</guid>
      <description>

&lt;h1 id=&#34;基于知识库的问答系统-kb-qa-paper推荐:d582df2b1cf9bb3616ee259c8891eb63&#34;&gt;基于知识库的问答系统 KB-QA paper推荐&lt;/h1&gt;

&lt;h2 id=&#34;注-文章推荐来自于知乎专栏-刘大一恒-作者:d582df2b1cf9bb3616ee259c8891eb63&#34;&gt;注：文章推荐来自于知乎专栏&amp;ndash;刘大一恒（作者）&lt;/h2&gt;

&lt;p&gt;由于毕设是问答系统，因此需要读相关的文献，刘博士这里推荐的都很不错。专门都下载下来，留下来自己研读，当然也推荐给大家。&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://pan.baidu.com/s/1hr4Q2LQ&#34;&gt;paper下载地址&lt;/a&gt; 密码：j6xp &lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;语义解析部分paper-br:d582df2b1cf9bb3616ee259c8891eb63&#34;&gt;语义解析部分paper&lt;br&gt;&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Berant J, Chou A, Frostig R, et al. Semantic Parsing on Freebase from Question-Answer Pairs[C]//EMNLP. 2013, 2(5): 6.&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Cai Q, Yates A. Large-scale Semantic Parsing via Schema Matching and Lexicon Extension[C]//ACL (1). 2013: 423-433.&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Kwiatkowski T, Choi E, Artzi Y, et al. Scaling semantic parsers with on-the-fly ontology matching[C]//In Proceedings of EMNLP. Percy. 2013.&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Fader A, Zettlemoyer L, Etzioni O. Open question answering over curated and extracted knowledge bases[C]//Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2014: 1156-1165.&lt;br&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;信息抽取-br:d582df2b1cf9bb3616ee259c8891eb63&#34;&gt;信息抽取&lt;br&gt;&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Yao X, Van Durme B. Information Extraction over Structured Data: Question Answering with Freebase[C]//ACL (1). 2014: 956-966.&lt;br&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;向量建模方法-br:d582df2b1cf9bb3616ee259c8891eb63&#34;&gt;向量建模方法&lt;br&gt;&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Bordes A, Chopra S, Weston J. Question answering with subgraph embeddings[J]. arXiv preprint arXiv:1406.3676, 2014.&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Yang M C, Duan N, Zhou M, et al. Joint Relational Embeddings for Knowledge-based Question Answering[C]//EMNLP. 2014, 14: 645-650.&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Bordes A, Weston J, Usunier N. Open question answering with weakly supervised embedding models[C]//Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer Berlin Heidelberg, 2014: 165-180.&lt;br&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;卷积神经网络对向量建模-br:d582df2b1cf9bb3616ee259c8891eb63&#34;&gt;卷积神经网络对向量建模&lt;br&gt;&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Dong L, Wei F, Zhou M, et al. Question Answering over Freebase with Multi-Column Convolutional Neural Networks[C]//ACL (1). 2015: 260-269.&lt;br&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;卷积神经网络对语义解析-br:d582df2b1cf9bb3616ee259c8891eb63&#34;&gt;卷积神经网络对语义解析&lt;br&gt;&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Yih S W, Chang M W, He X, et al. Semantic parsing via staged query graph generation: Question answering with knowledge base[J]. 2015. &lt;br&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;lstm-cnn实体分类-br:d582df2b1cf9bb3616ee259c8891eb63&#34;&gt;LSTM CNN实体分类&lt;br&gt;&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Xu Y, Mou L, Li G, et al. Classifying Relations via Long Short Term Memory Networks along Shortest Dependency Paths[C]//EMNLP. 2015: 1785-1794.&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Zeng D, Liu K, Lai S, et al. Relation Classification via Convolutional Deep Neural Network[C]//COLING. 2014: 2335-2344.（Best paper）&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Zeng D, Liu K, Chen Y, et al. Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks[C]//EMNLP. 2015: 1753-1762.&lt;br&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;记忆网络-注意力机制-br:d582df2b1cf9bb3616ee259c8891eb63&#34;&gt;记忆网络，注意力机制&lt;br&gt;&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Bordes A, Usunier N, Chopra S, et al. Large-scale simple question answering with memory networks[J]. arXiv preprint arXiv:1506.02075, 2015.&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Zhang Y, Liu K, He S, et al. Question Answering over Knowledge Base with Neural Attention Combining Global Knowledge Information[J]. arXiv preprint arXiv:1606.00979, 2016.&lt;br&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>IOError: No wkhtmltopdf executable found</title>
      <link>https://jingyihiter.github.io/2016/07/04/ioerror-no-wkhtmltopdf-executable-found</link>
      <pubDate>Mon, 04 Jul 2016 01:04:16 +0800</pubDate>
      
      <guid>https://jingyihiter.github.io/2016/07/04/ioerror-no-wkhtmltopdf-executable-found</guid>
      <description>&lt;p&gt;#IOError: No wkhtmltopdf executable found: &amp;ldquo;&amp;rdquo;&lt;/p&gt;

&lt;p&gt;python使用pdfkit中，如果使用pdfkit.from_url 或者pdfkit.from_string等，就会出现上述错误。而且如果你使用pip安装了 &lt;strong&gt;&lt;em&gt;wkhtmltopdf&lt;/em&gt;&lt;/strong&gt;，还是会出现这个问题：&lt;br&gt;
If this file exists please check that this process can read it. Otherwise please install wkhtmltopdf - &lt;a href=&#34;https://github.com/JazzCore/python-pdfkit/wiki/Installing-wkhtmltopdf&#34;&gt;https://github.com/JazzCore/python-pdfkit/wiki/Installing-wkhtmltopdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;因此需要去安装windows版本的&lt;strong&gt;&lt;em&gt;wkhtmltopdf&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;http://wkhtmltopdf.org/downloads.html&#34;&gt;此处进入下载网址&lt;/a&gt;&lt;br&gt;
安装完成之后需要在代码中添加以下内容：&lt;br&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;path_wk = r&#39;C:\Python27\wkhtmltopdf\bin\wkhtmltopdf.exe&#39; #安装位置
config = pdfkit.configuration(wkhtmltopdf = path_wk)
pdfkit.from_url(url, r&#39;D:\are you coding\pdf\taobao.pdf&#39;, configuration=config)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如此即可实现了&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>python学习——保存网页到本地 html及pdf</title>
      <link>https://jingyihiter.github.io/2016/07/04/python%E5%AD%A6%E4%B9%A0%E4%BF%9D%E5%AD%98%E7%BD%91%E9%A1%B5%E5%88%B0%E6%9C%AC%E5%9C%B0-html%E5%8F%8Apdf</link>
      <pubDate>Mon, 04 Jul 2016 01:04:01 +0800</pubDate>
      
      <guid>https://jingyihiter.github.io/2016/07/04/python%E5%AD%A6%E4%B9%A0%E4%BF%9D%E5%AD%98%E7%BD%91%E9%A1%B5%E5%88%B0%E6%9C%AC%E5%9C%B0-html%E5%8F%8Apdf</guid>
      <description>&lt;p&gt;#python学习——保存网页到本地 html及pdf&lt;/p&gt;

&lt;p&gt;直接上代码：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# -*- coding: utf-8 -*-
&amp;quot;&amp;quot;&amp;quot;
Created on Tue Jun 14 13:01:58 2016

@author: 
&amp;quot;&amp;quot;&amp;quot;

import urllib2
import cookielib
import pdfkit

cj = cookielib.LWPCookieJar()
opener = urllib2.build_opener(urllib2.HTTPCookieProcessor(cj))
urllib2.install_opener(opener)
url = &amp;quot;https://www.taobao.com/&amp;quot;
req = urllib2.Request(url)
&#39;&#39;&#39; 保存html到本地&#39;&#39;&#39;
operate = opener.open(req)
msg = operate.read()
document = &#39;D://1.html&#39;  
file_ = open(document,&#39;w&#39;)   
file_.write(msg)
file_.close()

path_wk = r&#39;C:\Python27\wkhtmltopdf\bin\wkhtmltopdf.exe&#39;
config = pdfkit.configuration(wkhtmltopdf = path_wk)

&#39;&#39;&#39;保存pdf到本地&#39;&#39;&#39;
pdfkit.from_url(url, r&#39;D:\are you coding\pdf\taobao.pdf&#39;, configuration=config)
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>GBN协议的实现</title>
      <link>https://jingyihiter.github.io/2016/07/01/gbn%E5%8D%8F%E8%AE%AE%E7%9A%84%E5%AE%9E%E7%8E%B0</link>
      <pubDate>Fri, 01 Jul 2016 00:30:47 +0800</pubDate>
      
      <guid>https://jingyihiter.github.io/2016/07/01/gbn%E5%8D%8F%E8%AE%AE%E7%9A%84%E5%AE%9E%E7%8E%B0</guid>
      <description>

&lt;h1 id=&#34;二-计算机网络之gbn协议的实现:a6ef90ec143a8509356ee3058751c59e&#34;&gt;二、计算机网络之GBN协议的实现&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/jingyihiter/GBN.git&#34;&gt;源码下载&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;实验内容-br:a6ef90ec143a8509356ee3058751c59e&#34;&gt;&lt;strong&gt;实验内容：&lt;/strong&gt;&lt;br&gt;&lt;/h2&gt;

&lt;p&gt;1) 基于UDP设计一个简单的GBN协议， 实现单向可靠数据传输 （服务器到客户的数据传输） 。&lt;br&gt;
2) 模拟引入数据包的丢失，验证所设计协议的有效性。&lt;br&gt;
3) 改进所设计的 GBN 协议，支持双向数据传输； （选作内容，加分项目，可以当堂完成或课下完成）&lt;br&gt;
4）将所设计的 GBN 协议改进为 SR 协议。 （选作内容，加分项目,可以当堂完成或课下完成）&lt;br&gt;
&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;实验原理及参考-br:a6ef90ec143a8509356ee3058751c59e&#34;&gt;实验原理及参考：&lt;br&gt;&lt;/h2&gt;

&lt;p&gt;实验原理图&lt;br&gt;
&lt;img src=&#34;https://github.com/jingyihiter/jingyihiter.github.io/raw/master/css/images/GBN.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;作为只实现单向数据传输的 GBN 协议，实质上就是实现为一个 C/S应用。&lt;br&gt;
服务器端：使用 UDP 协议传输数据（比如传输一个文件） ，等待客户端的请求，接收并处理来自客户端的消息（如数据传输请求） ，当客户端开始请求数据时进入“伪连接”状态（并不是真正的连接，只是一种类似连接的数据发送的状态） ，将数据打包成数据报发送，然后等待客户端的 ACK 信息，同时启动计时器。当收到ACK 时，窗口滑动，正常发送下一个数据报，计时器重新计时；若在计时器超时前没有收到 ACK，则全部重传窗口内的所以已发送的数据报。&lt;br&gt;
&lt;br&gt;
客户端：使用 UDP 协议向服务器端请求数据，接收服务器端发送的数据报并返回确认信息 ACK （注意 GBN 为累积确认， 即若 ACK=1 和 3，表示数据帧 2 已经正确接收） ，必须能够模拟 ACK 丢失直至服务器端超时重传的情况。&lt;br&gt;
&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;服务器端设计参考:a6ef90ec143a8509356ee3058751c59e&#34;&gt;服务器端设计参考&lt;/h2&gt;

&lt;p&gt;1）命令解析&lt;br&gt;
为了测试客户端与服务器端的通信交互，方便操作，设置了此过程。&lt;br&gt;
首先，服务器接收客户端发来的请求数据，&lt;br&gt;
“-time”表示客户端请求获取当前时间，服务器回复当前时间；&lt;br&gt;
“-quit”表示客户端退出，服务器回复“Good bye!”；&lt;br&gt;
“-testgbn”表示客户端请求开始测试 GBN 协议，服务器开始进入GBN 传输状态；其他数据，则服务器直接回复原数据。&lt;br&gt;&lt;br&gt;
2）数据传输数据帧格式定义&lt;br&gt;
在以太网中，数据帧的 MTU 为 1500 字节，所以 UDP 数据报的数据部分应小于 1472 字节（除去 IP 头部 20 字节与 UDP 头的 8 字节） ，为此，定义 UDP 数据报的数据部分格式为：&lt;br&gt;
&lt;img src=&#34;https://github.com/jingyihiter/jingyihiter.github.io/raw/master/css/images/seq.png&#34; alt=&#34;&#34; /&gt;
Seq 为 1 个字节，取值为 0~255， （故序列号最多为 256 个） ；Data≤1024 个字节，为传输的数据；
最后一个字节放入 EOF0，表示结尾&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;客户端设计参考:a6ef90ec143a8509356ee3058751c59e&#34;&gt;客户端设计参考&lt;/h2&gt;

&lt;p&gt;1) ACK 数据帧定义&lt;br&gt;
由于是从服务器端到客户端的单向数据传输， 因此 ACK 数据帧不包含任何数据，只需要将 ACK 发送给服务器端即可。&lt;br&gt;
&lt;img src=&#34;https://github.com/jingyihiter/jingyihiter.github.io/raw/master/css/images/ack.png&#34; alt=&#34;&#34; /&gt;
ACK 字段为一个字节，表示序列号数值；末尾放入 0，表示数据结束。&lt;br&gt;
2）命令设置&lt;br&gt;
客户端的命令和服务器端的解析命令向对应，获取当前用户输入并发送给服务器并等待服务器返回数据，如输入“-time”得到服务器的当前时间。&lt;br&gt;
此处重点介绍“-testgbn [X] [Y]”命令，[X],[Y]均为[0,1]的小数，其中：&lt;br&gt;
[X]表示客户端的丢包率，模拟网络中报文丢失；&lt;br&gt;
[Y]表示客户端的 ACK 的丢失率。 （使用随机函数完成） 。&lt;br&gt;
如果用户不输入，则默认丢失率均为 0.2&lt;br&gt;&lt;/p&gt;

&lt;p&gt;注：参考哈工大计算机网络指导书&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Http代理服务器</title>
      <link>https://jingyihiter.github.io/2016/07/01/http%E4%BB%A3%E7%90%86%E6%9C%8D%E5%8A%A1%E5%99%A8</link>
      <pubDate>Fri, 01 Jul 2016 00:24:46 +0800</pubDate>
      
      <guid>https://jingyihiter.github.io/2016/07/01/http%E4%BB%A3%E7%90%86%E6%9C%8D%E5%8A%A1%E5%99%A8</guid>
      <description>

&lt;h1 id=&#34;一-计算机网络之http代理服务器:7e45868971a7bcd8ef176d27cff9b534&#34;&gt;一、计算机网络之HTTP代理服务器&lt;/h1&gt;

&lt;p&gt;注：参考哈工大计算机网络指导书&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/jingyihiter/http_proxy&#34;&gt;源码下载地址&lt;/a&gt;&lt;br&gt;
&lt;br&gt;
实验的内容：&lt;br&gt;
1.实现基本的HTTP代理服务器,可以在指定端口接收客户端http的请求并且根据其中个URL地址访问该地址所指向的HTTP服务器，接收服务器的响应报文，并将响应报文转发给对应的客户进行浏览。&lt;br&gt;
2.设计并实现一个支持cache功能的HTTP代理服务器，要求能缓存原服务器响应的对象，并能够通过修改请求报文（添加 if-modified-since头行），向原服务器确认缓存对象是否是最新版本&lt;br&gt;
3.扩展 HTTP 代理服务器，支持如下功能：&lt;br&gt;
  a、网站过滤：允许/不允许访问某些网站&lt;br&gt;
  b、用户过滤：支持/不支持某些用户访问外部网站&lt;br&gt;
  c、网站引导：将用户对某个网站的访问引导至一个模拟网站（钓鱼）&lt;br&gt;
&lt;br&gt;
代理服务器，俗称 “翻墙软件” ，允许一个网络终端（一般为客户端）通过这个服务与另一个网络终端（一般为服务器）进行非直接的连接。如图所示，为普通 Web 应用通信方式与采用代理服务器的通信方式的对比。&lt;br&gt;
&lt;img src=&#34;https://github.com/jingyihiter/jingyihiter.github.io/raw/master/css/images/webhttp.png&#34; alt=&#34;&#34; /&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;实现的是多用户代理服务器，实现线程的并行执行。 首先，代理服务器创建 HTTP 代理服务的 TCP 主套接字，通过该主套接字监听等待客户端的连接请求。当客户端连接之后，创建一个子线程，由子线程执行上述一对一的代理过程，服务结束之后子线程终止。与此同时，主线程继续接受下一个客户的代理服务。&lt;br&gt;
&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;实验环境配置-br:7e45868971a7bcd8ef176d27cff9b534&#34;&gt;实验环境配置&lt;br&gt;&lt;/h2&gt;

&lt;p&gt;打开IE（windows）-&amp;gt; 工具 -&amp;gt; Internet选项 -&amp;gt; 连接 -&amp;gt; 局域网设置 -&amp;gt; 代理服务器 &lt;br&gt;
如下设置地址和端口号（端口号和程序中保持一致即可（最好使用较大的，低端口一般被占用））&lt;br&gt;
&lt;img src=&#34;https://github.com/jingyihiter/jingyihiter.github.io/raw/master/css/images/port.png&#34; alt=&#34;&#34; /&gt;&lt;br&gt;
&lt;br&gt;
&lt;strong&gt;基本的HTTP代理服务器，实现简单，不用处理直接转发接收到目的服务器的报文即可。因此不作介绍，主要讲解实现的扩展功能&lt;/strong&gt;。&lt;br&gt;
&lt;br&gt;
&lt;strong&gt;1网站过滤的实现&lt;/strong&gt;&lt;br&gt;
基本思想：通过解析客户端请求的buffer，获取请求的URL，然后设置关键字，再次使用c++中的一个函数&lt;strong&gt;strstr&lt;/strong&gt;，判断关键字是否在其子串中&lt;br&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bool ForbiddenToConnect(char *httpheader)
{
    char * forbiddernUrl = &amp;quot;.edu.cn&amp;quot;; //屏蔽的含有关键字的网址
    if (strstr(httpheader, forbiddernUrl)!=NULL) //是否含有屏蔽的关键字
    {
        return false;
    }
    else return true;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;
&lt;strong&gt;2用户过滤的实现&lt;/strong&gt;&lt;br&gt;
基本思想：通过客户端请求，获取请求用户的IP，然后在程序运行时，设置一个IP禁止表，在IP禁止表中存入一些IP地址，在请求之后就去查询是否在IP禁止表中，如果是，则关闭socket即可，等待下一次的请求。&lt;br&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;char client_IP[16];
//设置禁用IP,可以在此添加更多
memcpy(ForbiddenIP[IPnum++], &amp;quot;127.0.0.1&amp;quot;, 16);
//设置访问哪些网站会被重定向到钓鱼网站
memcpy(fishUrl[fishUrlnum++], &amp;quot;http://www.asus.com.cn/&amp;quot;,23);
memcpy(fishUrl[fishUrlnum++],&amp;quot;http://pku.edu.cn/&amp;quot;,18);
while (true) {
    int ff;
    ff = sizeof(acceptAddr);
    acceptSocket = accept(ProxyServer, (SOCKADDR*)&amp;amp;acceptAddr,&amp;amp;(ff));
    printf(&amp;quot;获取用户IP地址：%s\n&amp;quot;,inet_ntoa(acceptAddr.sin_addr));
    memcpy(client_IP, inet_ntoa(acceptAddr.sin_addr),16);//用户IP保存
    //禁用用户IP访问
    if (UserIsForbidden(client_IP))
    {
        printf(&amp;quot;IP被禁用\n&amp;quot;);
        closesocket(acceptSocket);
        //system(&amp;quot;pause&amp;quot;);
        //break;
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;
&lt;strong&gt;重点是&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;acceptSocket = accept(ProxyServer, (SOCKADDR*)&amp;amp;acceptAddr,&amp;amp;(ff));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;
获取请求IP的方法。如果最后一个参数设置的是0，则返回的IP一直是204.204.204.204，显然不是请求的IP地址，因此需要作上述处理，先获取acceptAddr的大小，然后其地址作为accept函数的地址&lt;br&gt;
&lt;br&gt;
&lt;strong&gt;3钓鱼网站的实现（钓鱼网站）&lt;/strong&gt;&lt;br&gt;
基本思想：设置一个钓鱼网站的URL表，如果请求的URL在此URL表中，则丢弃其的请求报文，转成302报文发送，在302报文中定位到钓鱼网站的网址，从而实现访问请求网站自动重定向到钓鱼网站&lt;br&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;//网站引导  访问pku.edu.cn  asus.com 重定向到 today.hit.edu.cn
if (GotoFalseWebsite(httpHeader-&amp;gt;url))
{   //302报文 对客户端的请求直接截断重定向到其他页面
        //数据内容主要的就两条：
        //&amp;quot;HTTP/1.1 302 Moved Temporarily&amp;quot;
        //&amp;quot;Location: 路径&amp;quot;
    //生成302报文，直接发送给客户端
    char* pr;  
    int fishing_len = strlen(&amp;quot;HTTP/1.1 302 Moved Temporarily\r\n&amp;quot;); //302报文
    memcpy(FishBuffer, &amp;quot;HTTP/1.1 302 Moved Temporarily\r\n&amp;quot;, fishing_len);
    pr = FishBuffer + fishing_len;
    //重定向到今日哈工大
    fishing_len = strlen(&amp;quot;Location: http://today.hit.edu.cn/\r\n\r\n&amp;quot;);  //定向的网址
    memcpy(pr, &amp;quot;Location: http://today.hit.edu.cn/\r\n\r\n&amp;quot;, fishing_len);
    //将302报文返回给客户端
    ret = send(((ProxyParam*)lpParameter)-&amp;gt;clientSocket, FishBuffer, sizeof(FishBuffer), 0);
    goto error;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;
&lt;strong&gt;4cache的实现&lt;/strong&gt;&lt;br&gt;
基本思想：cache作为代理服务器的缓存管理。首先，客户端请求报文，需要在cache中查询，如果命中，则进行访问目标服务器，缓存是否过期，未过期则直接将缓存的报文转发给客户端,过期则将目标服务器返回的报文进行更新cache；未命中，则直接请求目标服务器，将目标服务器的返回报文更新到cache中，并发送给客户端。&lt;br&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;//cache 实现
    if (Have_cache) //请求有缓存
    {
        char cached_buffer[MAXSIZE];//缓存buffer
        ZeroMemory(cached_buffer, MAXSIZE);
        memcpy(cached_buffer, Buffer, recvSize);

        //构造缓存的报文头
        char* pr = cached_buffer + recvSize;
        memcpy(pr, &amp;quot;If-modified-since: &amp;quot;, 19);
        pr += 19;
        int lenth = strlen(Cache[last_cache].last_modified);
        memcpy(pr, Cache[last_cache].last_modified, lenth);
        pr += lenth;
        //将客户端发送的 HTTP 数据报文直接转发给目标服务器
        ret = send(((ProxyParam *)lpParameter)-&amp;gt;serverSocket, cached_buffer, strlen(cached_buffer) + 1, 0);
        //等待目标服务器返回数据
        recvSize = recv(((ProxyParam *)lpParameter)-&amp;gt;serverSocket, cached_buffer, MAXSIZE, 0);
        if (recvSize &amp;lt;= 0) {
            goto error;
        }

        //解析包含缓存信息的HTTP报文头
        CacheBuffer = new char[recvSize + 1];
        ZeroMemory(CacheBuffer, recvSize + 1);
        memcpy(CacheBuffer, cached_buffer, recvSize);
        char last_status[4];//用于记录主机返回的状态字
        char last_modified[30];//用于记录记住返回的页面修改的时间
        ParseCache(CacheBuffer, last_status, last_modified);
        delete CacheBuffer;

        //分析cache的状态字
        if (strcmp(last_status, &amp;quot;304&amp;quot;) == 0) {//没有被修改
            printf(&amp;quot;页面没有修改过,缓存的url为:%s\n&amp;quot;, Cache[last_cache].url);
            //将缓存的数据直接转发给客户端
            ret = send(((ProxyParam*)lpParameter)-&amp;gt;clientSocket, Cache[last_cache].buffer, sizeof(Cache[last_cache].buffer), 0);
            if (ret != SOCKET_ERROR)
            {
                printf(&amp;quot;来自缓存++++++++++++++\n&amp;quot;);
            }
        }
        else if (strcmp(last_status, &amp;quot;200&amp;quot;) == 0) {//已经修改了
            //修改缓存中的内容
            printf(&amp;quot;页面已经被修改过,缓存的url为:%s\n&amp;quot;, Cache[last_cache].url);
            memcpy(Cache[last_cache].buffer, cached_buffer, strlen(cached_buffer));//新的buffer 存在缓存中
            memcpy(Cache[last_cache].last_modified, last_modified, strlen(last_modified)); //修改时间存入缓存

            //将目标服务器返回的数据直接转发给客户端
            ret = send(((ProxyParam*)lpParameter)-&amp;gt;clientSocket, cached_buffer, sizeof(cached_buffer), 0);
            if (ret != SOCKET_ERROR)
            {
                printf(&amp;quot;来自修改过的缓存-----------\n&amp;quot;);
            }
        }
    }
    else //没有缓存过这个页面
    {
        //将客户端发送的 HTTP 数据报文直接转发给目标服务器
        ret = send(((ProxyParam *)lpParameter)-&amp;gt;serverSocket, Buffer, strlen(Buffer) + 1, 0);
        if (ret != SOCKET_ERROR)
        {
            printf(&amp;quot;成功发送给目标服务器的报文buffer \n \n&amp;quot;);
        }
        //等待目标服务器返回数据
        recvSize = recv(((ProxyParam *)lpParameter)-&amp;gt;serverSocket, Buffer, MAXSIZE, 0);
        if (recvSize == SOCKET_ERROR)
        {
            printf(&amp;quot;目标服务器未返回数据\n&amp;quot;);
            goto error;
        }
        //将目标服务器返回的数据直接转发给客户端
        ret = send(((ProxyParam*)lpParameter)-&amp;gt;clientSocket, Buffer, sizeof(Buffer), 0);
        if (ret != SOCKET_ERROR)
        {
            printf(&amp;quot;来自服务器************\n成功发送给客户端的报文(目标服务器返回的)buffer ret = %d \n&amp;quot;, ret);
        }
    }
    //错误处理
error:
    printf(&amp;quot;关闭套接字\n&amp;quot;);
    Sleep(200);
    closesocket(((ProxyParam*)lpParameter)-&amp;gt;clientSocket);
    closesocket(((ProxyParam*)lpParameter)-&amp;gt;serverSocket);
    delete lpParameter;
    _endthreadex(0);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;
cache的报文头解析&lt;br&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;//*************************
//Method: ParseHttpHead0
//FullName: ParseHttpHead0
//Access: public
//Returns: void
//Qualifier: 解析 TCP 报文中的 HTTP 头部
//Parameter: char *buffer
//Parameter: HttpHeader *httpHeader
//*************************

int ParseHttpHead0(char *buffer, HttpHeader *httpHeader) {
    int flag = 0;//用于表示Cache是否命中，命中为1，不命中为0
    char *p;
    char *ptr;
    const char *delim = &amp;quot;\r\n&amp;quot;;//回车换行符                           
    p = strtok_s(buffer, delim, &amp;amp;ptr);
    if (p[0] == &#39;G&#39;) {  //GET方式
        memcpy(httpHeader-&amp;gt;method, &amp;quot;GET&amp;quot;, 3);
        memcpy(httpHeader-&amp;gt;url, &amp;amp;p[4], strlen(p) - 13);
        printf(&amp;quot;url：%s\n&amp;quot;, httpHeader-&amp;gt;url);//url                                       
        for (int i = 0; i &amp;lt; 1024; i++) {//搜索cache，看当前访问的url是否已经存在cache中了
            if (strcmp(Cache[i].url, httpHeader-&amp;gt;url) == 0) {//说明url在cache中已经存在
                flag = 1;   //只要存在，flag标识变量置为1
                break;
            }
        }
        if (!flag &amp;amp;&amp;amp; cached_number != 1023) {//说明url没有在cache且cache没有满, 把这个url直接存进去
            memcpy(Cache[cached_number].url, &amp;amp;p[4], strlen(p) - 13);
            last_cache = cached_number;
        }
        else if (!flag &amp;amp;&amp;amp; cached_number == 1023) {//说明url没有在cache且cache满了
            //为了简单，替换第一个
            memcpy(Cache[0].url, &amp;amp;p[4], strlen(p) - 13);
            last_cache = 0;
        }
    }
    else if (p[0] == &#39;P&#39;) { //POST方式
        memcpy(httpHeader-&amp;gt;method, &amp;quot;POST&amp;quot;, 4);
        memcpy(httpHeader-&amp;gt;url, &amp;amp;p[5], strlen(p) - 14);
        for (int i = 0; i &amp;lt; 1024; i++) {
            if (strcmp(Cache[i].url, httpHeader-&amp;gt;url) == 0) { //同上
                flag = 1;
                break;
            }
        }
        if (!flag &amp;amp;&amp;amp; cached_number != 1023) {
            memcpy(Cache[cached_number].url, &amp;amp;p[5], strlen(p) - 14);
            last_cache = cached_number;
        }
        else if (!flag &amp;amp;&amp;amp; cached_number == 1023) {
            memcpy(Cache[0].url, &amp;amp;p[4], strlen(p) - 13);
            last_cache = 0;
        }
    }

    p = strtok_s(NULL, delim, &amp;amp;ptr);
    while (p) {
        switch (p[0]) {
        case &#39;H&#39;://HOST
            memcpy(httpHeader-&amp;gt;host, &amp;amp;p[6], strlen(p) - 6);
            if (!flag &amp;amp;&amp;amp; cached_number != 1023) {
                memcpy(Cache[last_cache].host, &amp;amp;p[6], strlen(p) - 6);
                cached_number++;
            }
            else if (!flag &amp;amp;&amp;amp; cached_number == 1023) {
                memcpy(Cache[last_cache].host, &amp;amp;p[6], strlen(p) - 6);
            }
            break;
        case &#39;C&#39;://Cookie
            if (strlen(p) &amp;gt; 8) {
                char header[8];
                ZeroMemory(header, sizeof(header));
                memcpy(header, p, 6);
                if (!strcmp(header, &amp;quot;Cookie&amp;quot;)) {
                    memcpy(httpHeader-&amp;gt;cookie, &amp;amp;p[8], strlen(p) - 8);
                }
            }
            break;
            //case &#39;&#39;:
        default:
            break;
        }
        p = strtok_s(NULL, delim, &amp;amp;ptr);
    }
    return flag;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;
&lt;strong&gt;&lt;a href=&#34;https://github.com/jingyihiter/http_proxy&#34;&gt;重复一遍，源码地址&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>resume</title>
      <link>https://jingyihiter.github.io/2016/06/30/resume</link>
      <pubDate>Thu, 30 Jun 2016 23:30:25 +0800</pubDate>
      
      <guid>https://jingyihiter.github.io/2016/06/30/resume</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://github.com/jingyihiter/jingyihiter.github.io/raw/master/myresume.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>